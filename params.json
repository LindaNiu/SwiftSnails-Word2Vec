{"name":"SwiftSnails-Word2Vec","tagline":"一个分布式的Word2Vec实现","body":"# SwiftSnails-Word2Vec\r\nSwiftSnails-Word2Vec 是一个高性能的分布式Word2Vec分布式实现。\r\n\r\n如果你需要从大量的文本数据（大于30G)，词向量，可以使用本项目， 修改一些配置就可以直接运行。\r\n\r\n也可以访问 http://yun.baidu.com/s/1gdgYkiZ 获取（这是我们之前生成的一套词向量，64G数据+43w词库）。\r\n\r\n## 编译方法\r\n本项目直接依赖SwiftSnails参数服务器，请提前下载SwiftSnails，并安装所有的第三方依赖。\r\n\r\n之后在Makefile中作如下配置:\r\n\r\n```\r\n# 下载的SwiftSnails的src目录\r\nSwiftSnails_src=...\r\n\r\n# SwiftSnails所有第三方依赖库安装目录\r\nLOCAL_ROOT...\r\n```\r\n\r\n之后编译：\r\n```\r\n$ mkdir bin\r\n$ make\r\n```\r\n\r\n所有产出的可执行文件在 `bin/` 目录中，具体内容如下\r\n\r\n```\r\nswift_worker    # 计算节点\r\nswift_server    # 参数服务器节点\r\nswift_lworker   # 内存优化的word2vec计算节点\r\nswift_master    # 中央控制节点\r\n```\r\n\r\n一个完整的任务执行需要包括 *worker* ， *server* ， *master* 三种节点的协作。\r\n\r\n其中 worker 节点有两种实现： \r\n\r\n* swift_worker : 常规的CBOW+Negative-Sampling 实现\r\n* swift_worker : 内存优化的版本，通过minibatch的方式控制内存消耗，一般可以降一个数量级\r\n\r\n## 节点配置\r\nSwiftSnails中需要三类节点的配置，此处基准配置在 `config/` 目录中\r\n\r\n### common.conf\r\n```\r\n# 是否对传输消息进行压缩\r\n# 0 表示不压缩，数值越大，压缩比例越大\r\nzlib : 0~9 数值\r\n```\r\n\r\n### master.conf\r\n```\r\n# master 节点侦听地址\r\nlisten_addr: tcp://127.0.0.1:16831\r\n\r\n# master 守候进程数\r\nasync_exec_num: 4\r\n\r\n# worker节点数 + server节点数（必须要配置）\r\nexpected_node_num: 4\r\n\r\n# 初始化等待时长，超时后，master将不再接受节点登记，单位为秒\r\nmaster_time_out: 120\r\n\r\n# 参数分块数，便于参数拆分，可以设置为 server数目 * 3\r\nfrag_num: 50\r\n```\r\n\r\n### worker.conf\r\n```\r\n# worker守候地址，可以不配置，节点会自动获取本机ip及随机端口\r\nlisten_addr:\r\n\r\n# 守候线程数目\r\nasync_exec_num: 2\r\n\r\n# 初始化超时 最好和 master_time_out 设置相同时间\r\ninit_timeout: 60\r\n\r\n# master的监听地址，需要和 master.conf中的listen_addr 相同\r\nmaster_addr: tcp://127.0.0.1:16831\r\n\r\n# 计算线程数目，最好设置为CPU核数\r\nasync_channel_thread_num\r\n\r\n# 迭代次数 如果数据比较大，只需要1轮迭代\r\nnum_iters: 1\r\n\r\n# 文件读取缓存，单位为行\r\nline_buffer_queue_capacity : 100\r\n```\r\n\r\n### server.conf\r\n类似配置参考 *worker.conf*\r\n```\r\n# 单个server上的参数分块数（由于采用了读写锁，拆分多个shard后可以提升性能)\r\n# 可以设置多一点 30+ 300+ 都可以\r\nshard_num: 5\r\n\r\n# 执行过程中的参数备份的周期 \r\n# 备份的周期单位为PUSH的次数\r\n# 一轮迭代的PUSH次数可以通过 单个节点训练数据行数 / minibatch长度\r\nparam_backup_period: 0\r\nparam_backup_root: ./param_back/\r\n\r\n# 是否使用AdaGrad，0表示非, 1表示是\r\nadagrad: 1\r\n```\r\n\r\n### word2vec.conf\r\n```\r\n# 词向量维度\r\nlen_vec: 100\r\n\r\n# 初始的学习率\r\nlearning_rate: 0.5\r\n\r\n# CBOW 窗口长度\r\nwindow: 4\r\n\r\n# 负例个数\r\nnegative: 20\r\n\r\n# 高频采样\r\nsample: 0.001\r\n\r\n# minibatch 长度\r\nnum_sents_to_cache: 10000\r\n```\r\n\r\n\r\n## 集群配置\r\n本项目不包含任何执行任务之外的功能实现，无法：\r\n\r\n* 分发数据\r\n* 分发任务\r\n* 任务控制\r\n\r\n但提供了一些简单的脚本，我们在实际的词向量生成任务中也是使用的这套脚本。\r\n\r\n**集群配置**\r\n\r\n需要在集群中一个节点上执行 *swift_master* ，此节点称为控制节点。\r\n\r\n为了方便脚本使用 **ssh** 的方式批量执行命令，需要建立控制节点与其他节点的ssh_key 免密码登陆。\r\n\r\n之后可以使用 *tools* 中的脚本工具。\r\n\r\n在 *common.sh* 中配置集群中的节点IP列表，以及一系列的环境变量\r\n\r\n之后的集群执行包括：\r\n\r\n* copy_exec.sh 复制二进制文件到当前目录\r\n* dist_demo.sh 在common.sh中配置的节点中分发任务\r\n* dist_kill_demo.sh kill集群任务\r\n* dist_log.sh 搜集最新的执行\r\n* dist_collect_parameter.sh 任务执行完毕，汇总集群中各server产生的参数\r\n\r\n## 两种模式\r\n前面讲到 swift_worker 和 swift_lworker 两种计算节点，两种节点的差别是单个节点的参数缓存的规模。\r\n\r\n* swift_worker : 单个worker节点缓存本节点中训练数据涉及的参数\r\n* swift_lworker : 单个节点只缓存一个minibatch中涉及的参数\r\n\r\n一般前者和后者所占用内存规模相差一个数量级。 \r\n前者在Negative-Sampling中噪音采样的范围大很多，效果也比后者好。\r\n\r\n后者的内存占用小很多，可以训练高维向量（比如500维以上)。\r\n\r\n# 性能和实测\r\n* 68G 分词后中文文本(来自 Web Infomall)\r\n* 100维向量生成\r\n* 单个节点配置: Inter(R) Xeon(R) CPU E5620 @2.40GHz  内存40G\r\n* 集群节点数：8 \r\n* 单节点线程数: 12\r\n* 总词数：9,728,259,104 \r\n* 运行总时长： 4h20s\r\n* 词吞吐率：675k words/s\r\n\r\n# 联系作者\r\n\r\nWeibo: @superjom\r\n\r\nmailTo: yanchunwei[A|T-]outlook.com\r\n","google":"","note":"Don't delete this file! It's used internally to help with page regeneration."}